{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fabc549-0492-47e0-bb02-47ccf21039cf",
   "metadata": {},
   "source": [
    "Nicholas Beard\n",
    "CST407 Artifical Intelligence\n",
    "Container Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676071db-c148-4ddc-9bc8-c60d28d6585d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c80d0b-24cc-4d48-ad81-ec3302e1c240",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data set parameters\n",
    "batch_size = 64\n",
    "image_height = 512\n",
    "image_width = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24f68b1-3deb-466d-a929-d24ae9d861c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number and names of classes we are identifying\n",
    "# These need to match file names in loaded image directory\n",
    "class_names=[\"SmallBottle\",\"LargeBottle\",\"Can\",\"Empty\"]\n",
    "class_count = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3467ff-efbc-45e8-8407-d415c207a498",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Establish datapath #\n",
    "data_path = os.path.join(\"Datasets\", \"MyCanBottle\", \"\")\n",
    "#this data path is used to store output files from webcam.\n",
    "unlabeled_output_data_path = os.path.join(\"Datasets\", \"CanBottleUnlabeled\", \"\")\n",
    "labeled_testing_data_path =  os.path.join(\"Datasets\", \"CanBottleTesting\", \"\")\n",
    "model_path = os.path.join(\"Models\", \"MyCanBottle\", \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c2f4a6-a126-4abc-b2d6-65de4fea41e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1732 files belonging to 4 classes.\n",
      "Using 1386 files for training.\n",
      "Found 1732 files belonging to 4 classes.\n",
      "Using 346 files for validation.\n",
      "Found 202 files belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load training data into datasets #\n",
    "seed = 242\n",
    "validation_split = 0.2\n",
    "train = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_path,\n",
    "    class_names=class_names,\n",
    "    seed=seed,\n",
    "    batch_size=batch_size,\n",
    "    image_size=(image_height, image_width),\n",
    "    validation_split=validation_split,\n",
    "    subset=\"training\")\n",
    "# Load testing data into datasets #\n",
    "test = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_path,\n",
    "    class_names=class_names,\n",
    "    seed=seed,\n",
    "    batch_size=batch_size,\n",
    "    image_size=(image_height, image_width),\n",
    "    validation_split=validation_split,\n",
    "    subset=\"validation\")\n",
    "secondary_test = tf.keras.utils.image_dataset_from_directory(\n",
    "    labeled_testing_data_path,\n",
    "    class_names=class_names,\n",
    "    seed=seed,\n",
    "    batch_size=1,\n",
    "    image_size=(image_height, image_width))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24200d53-41a2-42e8-8ce9-37ace6ca80aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202/202 [==============================] - 7s 31ms/step - loss: 0.4080 - accuracy: 0.8218\n"
     ]
    }
   ],
   "source": [
    "model_save_path = model_path +'BestWorkingModel-32-32-16-64d-8e.hdf5'\n",
    "try:\n",
    "    model = keras.models.load_model(model_save_path)\n",
    "    model.evaluate(secondary_test)\n",
    "except: \n",
    "    print(\"load failed\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef4de09-3feb-468a-a272-d4d6a7c9a113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling (Rescaling)       (None, 512, 512, 3)       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 510, 510, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 255, 255, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 253, 253, 32)      9248      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 126, 126, 32)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 124, 124, 16)      4624      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 62, 62, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 61504)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                3936320   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,951,348\n",
      "Trainable params: 3,951,348\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14f7e72-1c93-4fca-924f-5ed1b2fcb880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 8s 1s/step - loss: 0.0757 - accuracy: 0.9740\n"
     ]
    }
   ],
   "source": [
    "model_save_path = model_path +'SecondWorkingModel-32-32-16-64d-6e-softmax.hdf5'\n",
    "# Attempt to load pretrained model #\n",
    "try:\n",
    "    model = keras.models.load_model(model_save_path)\n",
    "    model.evaluate(test)\n",
    "\n",
    "except: \n",
    "    # If not able to be loaded, generate and train the model #\n",
    "    model = tf.keras.Sequential()\n",
    "    # normalization layer, rescales pixel data between 0-1 #\n",
    "    model.add(tf.keras.layers.Rescaling(1./255))  \n",
    "\n",
    "    # Convolutional Layer, 32 filters, kernal size 3, \n",
    "    model.add(tf.keras.layers.Conv2D(32, 3, activation='relu'))\n",
    "    # Pooling Layer #\n",
    "    model.add(tf.keras.layers.MaxPooling2D())    \n",
    "\n",
    "    # Convolutional Layer, 32 filters, kernal size 3, \n",
    "    model.add(tf.keras.layers.Conv2D(32, 3, activation='relu'))\n",
    "    # Pooling Layer #\n",
    "    model.add(tf.keras.layers.MaxPooling2D())    \n",
    "\n",
    "    # Convolutional Layer, 16 filters, kernal size 3, \n",
    "    model.add(tf.keras.layers.Conv2D(16, 3, activation='relu'))\n",
    "    # Pooling Layer #\n",
    "    model.add(tf.keras.layers.MaxPooling2D())    \n",
    "\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    \n",
    "    model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(class_count))\n",
    "    \n",
    "    #Normalize output as probabilities through softmax function\n",
    "    model.add(tf.keras.layers.Softmax())\n",
    "    \n",
    "    # Sparse catagorical cross entropy is used because of performance improvements over catagorical cross entropy. \n",
    "    # Values are loaded directly from logits, instead of being normalized by softmax first\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=['accuracy'])\n",
    "   \n",
    "    model.fit(\n",
    "        train,\n",
    "        validation_data=test,\n",
    "        epochs=6)\n",
    "    model.save(model_save_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc73528-ed84-4e6b-a66e-855e9a274aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_4 (Rescaling)     (None, 512, 512, 3)       0         \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 510, 510, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 255, 255, 32)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 253, 253, 32)      9248      \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 126, 126, 32)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 124, 124, 16)      4624      \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPoolin  (None, 62, 62, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 61504)             0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                3936320   \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      " softmax_4 (Softmax)         (None, 4)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,951,348\n",
      "Trainable params: 3,951,348\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b72b112-0463-4855-ab79-a5d254e2e92d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202/202 [==============================] - 7s 32ms/step - loss: 0.3313 - accuracy: 0.8416\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(secondary_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62299b0f-f1f2-4653-baf1-b535e1f755e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d18aeb3-a8be-456e-88e0-962cdf0e5081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 files belonging to 1 classes.\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "Escape hit, closing...\n"
     ]
    }
   ],
   "source": [
    "# Webcam Classification - Frame by Frame #\n",
    "cam = cv2.VideoCapture(0)\n",
    "cam.set(cv2.CAP_PROP_FRAME_WIDTH,1200);\n",
    "cam.set(cv2.CAP_PROP_FRAME_HEIGHT,720);\n",
    "cv2.namedWindow(\"test\")\n",
    "\n",
    "prediction_string = \"None\" \n",
    "prediction_values = \"\"\n",
    "# Camera read loop\n",
    "while True:\n",
    "    # read frame from camera\n",
    "    check, frame = cam.read()\n",
    "    if not check:\n",
    "        print(\"Failed\")\n",
    "        break\n",
    "    \n",
    "    # Write image to directory to be classified\n",
    "    img_name = \"classification.png\"\n",
    "    cv2.imwrite(unlabeled_output_data_path + \"/Classified/\" + img_name, frame)\n",
    "        \n",
    "    input_data = tf.keras.utils.image_dataset_from_directory(\n",
    "        unlabeled_output_data_path, \n",
    "        image_size=(image_height, image_width))\n",
    "    # Make a prediction\n",
    "    prediction = model.predict(input_data)\n",
    "    \n",
    "    # process prediction into strings\n",
    "    prediction_values = \"Small Bottle:\" + str(prediction[0][0]) + \"  Large Bottle:\" + str(prediction[0][1]) + \"  Can:\" + str(prediction[0][2]) + \"  Empty:\" + str(prediction[0][3])\n",
    "    \n",
    "    # Could expand here to post process batches of images, compounding certainty values across a batch\n",
    "    # Right now there is only one image per batch in prediction\n",
    "    for pred in prediction:\n",
    "        if(pred[0] > pred[1] and pred[0] > pred[2] and pred[0] > pred[3]):\n",
    "            prediction_string=\"Small Bottle\"\n",
    "        elif(pred[1] > pred[2] and pred[1] > pred[3]):\n",
    "            prediction_string=\"Large Bottle\"\n",
    "        elif(pred[2] > pred[3]):\n",
    "            prediction_string=\"Can\"\n",
    "        else:\n",
    "            prediction_string=\"Empty\"\n",
    "       \n",
    "\n",
    "    # Draw classification text on image\n",
    "    position = (50,150)   \n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    size = 2\n",
    "    color = (0, 0, 0)\n",
    "    cv2.putText(frame, prediction_string, position, font, size, color, 1, cv2.LINE_AA)\n",
    "    \n",
    "    # Draw confidence text on image\n",
    "    position = (45,250)   \n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    size = .5\n",
    "    color = (0, 0, 0)\n",
    "    cv2.putText(frame, prediction_values, position, font, size, color, 1, cv2.LINE_AA)\n",
    "    \n",
    "    #Display image with text on it\n",
    "    cv2.imshow(\"test\", frame)         \n",
    "    \n",
    "    # Exit on ESC press\n",
    "    keypress = cv2.waitKey(1) \n",
    "    if keypress%256 == 27: \n",
    "        # ESC pressed\n",
    "        print(\"Escape hit, closing...\")\n",
    "        break\n",
    "\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3fd9bd2-aef5-4c17-9b33-01a3f6b53dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#file names of captured images are stored in the format classification{i} \n",
    "#removal of i from the cell below allows it to be manually reset.\n",
    "i = 0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e093a454-417a-435b-862b-21842f1aca97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Capture training data from webcam\n",
    "cam = cv2.VideoCapture(0)\n",
    "cam.set(cv2.CAP_PROP_FRAME_WIDTH,1200);\n",
    "cam.set(cv2.CAP_PROP_FRAME_HEIGHT,720);\n",
    "cv2.namedWindow(\"Capture\")\n",
    "\n",
    "while True:\n",
    "    check, frame = cam.read()\n",
    "    if not check:\n",
    "        print(\"Failed\")\n",
    "        break\n",
    "        \n",
    "    cv2.imshow(\"test\", frame)\n",
    "    keypress = cv2.waitKey(1) \n",
    "    \n",
    "    if (keypress%256 == 32):\n",
    "        # Space has been pressed, capture an image and increment file name\n",
    "        img_name = \"classification{}.png\".format(i)\n",
    "        cv2.imwrite(unlabeled_output_data_path + \"/Classified/\" + img_name, frame)\n",
    "        i+=1;\n",
    "    elif (keypress%256 == 27):  \n",
    "        # ESC has been pressed\n",
    "        break\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518bc107-fc12-4037-9ff6-7fba6695e6eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
